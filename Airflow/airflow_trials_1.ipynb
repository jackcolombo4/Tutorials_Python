{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.2;\">\n",
    "\n",
    "<h1 style=\"color:darkturquoise; margin-bottom: 0.3em;\">Airflow tutorial 1 </h1>\n",
    "\n",
    "<p style=\"margin-top: 0.5em; margin-bottom: 1.5em;\"><strong> Basics concepts for dealing with workflows </strong></p>\n",
    "\n",
    "<div style=\"line-height:1.4; margin-bottom: 1em;\">\n",
    "    <h3 style=\"color: lightblue; display: inline; margin-right: 0.5em;\">Keywords:</h3>\n",
    "    <span style=\"display: inline;\">DAG creation + terminal commands to launch airflow + attributes included in default_args + bashoperator + Jinja templating + depends_on_past + shedule options </span>\n",
    "</div>\n",
    "\n",
    "<div style=\"line-height:1.4; margin-top: 1em;\">\n",
    "    <h3 style=\"color: red; display: inline; margin-right: 0.5em;\">Notes:</h3>\n",
    "    <span style=\"display: inline;\">\n",
    "    Jupyter Notebooks must be converted to Python Script to work, since not designed for task scheduling and workflow management. <br>\n",
    "    All the dags \".py\" files need to be placed and place it in the Airflow's dags folder. => ~/airflow/dags (or the dir specified in the \"airflow.cfg\" config file) <br>\n",
    "    In Apache Airflow, it is possible to define multiple DAGs into the same Python file. It is not mandatory having separate file for each DAG. <br>\n",
    "    </span>\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping, it's already installed\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping, it\\'s already installed\n",
    "!pip install python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import calendar\n",
    "import textwrap\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.rrule import rrule, DAILY\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from airflow import DAG\n",
    "#from airflow.operators.python_operator import PythonOperator           #deprecated!\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.operators.bash import BashOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Define the dictionary of default parameters that will be used when creating tasks, that are explicitly passed to the DAG.\"\"\"\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2024, 1, 14),\n",
    "    #'email': ['your_email@example.com'],\n",
    "    #'email_on_failure': False,\n",
    "    #'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkturquoise;\"> Recap: DAG </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "A Directed Acyclic Graph (DAG) is a collection of tasks organized to reflect their relationships and dependencies in a workflow.  <br>\n",
    "Where nodes represent tasks, and edges represent the dependencies between them. <br>\n",
    "DAGs, the tasks are directed, indicating that each task has a predefined execution path. <br>\n",
    "=> Each DAG in Airflow represents a separate workflow, and tasks belong to a specific DAG. <br>\n",
    "=> When a DAG is scheduled to run periodically, each scheduled run of the DAG is considered a separate instance. \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: darkturquoise;\"> Example #1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_1 = DAG('first_dag_example', \n",
    "            default_args=default_args, \n",
    "            description='A simple DAG to write current time to a file',\n",
    "            schedule=timedelta(days=1))     #schedule_interval=@daily is deprecated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1_for_first_operator():\n",
    "    \"\"\" Write the current date and time into a text file.\\\\\n",
    "    A Simple method to try Airflow, it doesn't require external APIs.\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    with open(\"current_time.txt\", \"a\") as file:\n",
    "        file.write(f\"Current Date and Time: {current_time}\\n\")\n",
    "\n",
    "    print(f\"I have written to file this: Current Date and Time are => {current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an operator => a task\n",
    "write_time_task = PythonOperator(\n",
    "    task_id='get_date_#1',\n",
    "    python_callable=function_1_for_first_operator,\n",
    "    dag=dag_1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(PythonOperator): first_task_get_date>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_time_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendar for January 2024\n",
      "Mo Tu We Th Fr Sa Su\n",
      " 1 2*  3  4 5*  6 7* \n",
      " 8  9 10* 11 12* 13 14* \n",
      "15 16 17* 18 19 20* 21 \n",
      "22* 23 24 25 26 27* 28* \n",
      "29 30 31             \n",
      "\n",
      "Meetings this month:\n",
      "- 2024-01-02: Team Introduction\n",
      "- 2024-01-05: Project Kickoff and Vision Sharing\n",
      "- 2024-01-07: Initial Requirements Gathering\n",
      "- 2024-01-10: Technology Stack Discussion\n",
      "- 2024-01-12: Development Workflow Setup\n",
      "- 2024-01-14: First Sprint Planning\n",
      "- 2024-01-17: Coding Standards Review\n",
      "- 2024-01-20: Progress Check and Feedback\n",
      "- 2024-01-22: Code Review Process\n",
      "- 2024-01-27: Preparation for First Commit\n",
      "- 2024-01-28: First Commit Celebration\n"
     ]
    }
   ],
   "source": [
    "def function_2_for_second_operator():\n",
    "    \"\"\" Define a list of meetings. Each meeting is a dictionary with date and topic.\n",
    "    \n",
    "    Notes:\n",
    "        - Days outside the current month are represented by 0\n",
    "        - A Newline represents at the end of the week\n",
    "    \"\"\"\n",
    "    meetings = [\n",
    "        {\"date\": datetime(2024, 1, 2), \"topic\": \"Team Introduction\"},\n",
    "        {\"date\": datetime(2024, 1, 5), \"topic\": \"Project Kickoff and Vision Sharing\"},\n",
    "        {\"date\": datetime(2024, 1, 7), \"topic\": \"Initial Requirements Gathering\"},\n",
    "        {\"date\": datetime(2024, 1, 10), \"topic\": \"Technology Stack Discussion\"},\n",
    "        {\"date\": datetime(2024, 1, 12), \"topic\": \"Development Workflow Setup\"},\n",
    "        {\"date\": datetime(2024, 1, 14), \"topic\": \"First Sprint Planning\"},\n",
    "        {\"date\": datetime(2024, 1, 17), \"topic\": \"Coding Standards Review\"},\n",
    "        {\"date\": datetime(2024, 1, 20), \"topic\": \"Progress Check and Feedback\"},\n",
    "        {\"date\": datetime(2024, 1, 22), \"topic\": \"Code Review Process\"},\n",
    "        {\"date\": datetime(2024, 1, 27), \"topic\": \"Preparation for First Commit\"},\n",
    "        {\"date\": datetime(2024, 1, 28), \"topic\": \"First Commit Celebration\"},\n",
    "    ]\n",
    "\n",
    "    ##### Create the calendar\n",
    "    year, month = 2024, 1\n",
    "    first_day_of_month = datetime(year, month, 1)\n",
    "    last_day_of_month = first_day_of_month + relativedelta(months=1, days=-1)\n",
    "    cal = calendar.monthcalendar(year, month)\n",
    "\n",
    "    ############################## Display the calendar\n",
    "    print(\"Calendar for\", calendar.month_name[month], year)\n",
    "    days = \"Mo Tu We Th Fr Sa Su\"\n",
    "    print(days)\n",
    "    for week in cal:\n",
    "        for day in week:\n",
    "            if day == 0:\n",
    "                print(\"   \", end=\"\") \n",
    "            else:\n",
    "                date = datetime(year, month, day)\n",
    "                meeting_topics = [m[\"topic\"] for m in meetings if m[\"date\"].date() == date.date()]\n",
    "                day_str = str(day) if not meeting_topics else f\"{day}*\"\n",
    "                print(f\"{day_str:>2} \", end=\"\")\n",
    "        print()  \n",
    "\n",
    "    print(\"\\nMeetings this month:\")\n",
    "    for meeting in meetings:\n",
    "        if first_day_of_month <= meeting[\"date\"] <= last_day_of_month:\n",
    "            print(f\"- {meeting['date'].strftime('%Y-%m-%d')}: {meeting['topic']}\")\n",
    "\n",
    "function_2_for_second_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create second operator \n",
    "create_meetings_task = PythonOperator(\n",
    "    task_id='create_meetings_table_#2',\n",
    "    python_callable=function_2_for_second_operator,\n",
    "    dag=dag_1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(PythonOperator): create_meetings_table>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a dependency\n",
    "write_time_task >> create_meetings_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkturquoise;\"> Recap: start Airflow Web-UI </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "\n",
    "\n",
    "Frist and Foremost\n",
    "- Set up the Airflow database with all necessary tables:\n",
    "    $airflow db init\n",
    "- Deprecated! Use this instead \n",
    "    $airflow db migrate\n",
    "\n",
    "- Create user: (no need to shut down the connection)\n",
    "    $airflow users create --username admin --password mysecurepassword --firstname John --lastname Doe --role Admin --email johndoe@ example.com\n",
    "\n",
    "- Launch on different terminals:\n",
    "\n",
    "    - $airflow webserver --port 8080\n",
    "    - $airflow scheduler \n",
    "<div>\n",
    "\n",
    "- Open Airflow in the browser to use DAGS on Web-UI => http://localhost:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkturquoise;\"> Notes: Extra SW to install </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "\n",
    "\n",
    "Use the command: <br>\n",
    "    $pip install connexion[swagger-ui] <br>\n",
    "=> To avoid the warning: Missing Swagger UI directory when using Connexion. <br>\n",
    "The Swagger UI is a web-based UI that allows the interactaction with the API documentation. <br>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: darkturquoise;\"> Example #2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_arg_2={\n",
    "    \"depends_on_past\": False,\n",
    "    \"email\": [\"airflow@example.com\"],\n",
    "    \"email_on_failure\": False,\n",
    "    \"email_on_retry\": False,\n",
    "    \"retries\": 1,\n",
    "    \"retry_delay\": timedelta(minutes=5),\n",
    "    # 'queue': 'bash_queue',\n",
    "    # 'pool': 'backfill',\n",
    "    # 'priority_weight': 10,\n",
    "    # 'end_date': datetime(2016, 1, 1),\n",
    "    # 'wait_for_downstream': False,\n",
    "    # 'sla': timedelta(hours=2),\n",
    "    # 'execution_timeout': timedelta(seconds=300),\n",
    "    # 'on_failure_callback': some_function,             # works also with a list of funcs\n",
    "    # 'on_success_callback': some_other_function,       # works also with a list of funcs\n",
    "    # 'on_retry_callback': another_function,            # works also with a list of funcs\n",
    "    # 'sla_miss_callback': yet_another_function,        # works also with a list of funcs\n",
    "    # 'trigger_rule': 'all_success'\n",
    "},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkturquoise;\"> Recap: textwrap </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "textwrap is a module used for formatting text by adjusting the line breaks in the input string.  <br>\n",
    "Useful to display text in a specific width in console applications or when dealing with text in a limited-space environment (e.g. a UI element).\n",
    "\n",
    "The primary use of textwrap is to wrap or fill text: <br>\n",
    "- Wrapping => means breaking a single long line into multiple lines of a specific width <br>\n",
    "- Filling => means converting a single paragraph into a single string with newlines to separate lines\n",
    "\n",
    "textwrap can also be used to: <br>\n",
    "_Adjusting Indentation <br>\n",
    "_Handling Whitespace <br>\n",
    "_Customizing Word Splitting <br>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create the graps (args will get passed on to each operator)\n",
    "Avoid adding \"dag=dag\" in each tasks definition, creating the methods for all operators inside the DAG definition.\n",
    "Thanks to the \"Context Manager\" approach, using the \"with statement\", a temporary context can be set up and reliably torn it down under various conditions. \n",
    "It is just a convenient way to manage resources such as file streams, database connections, or anything else that needs to be SET UP and then CLEANED up.\n",
    "\n",
    "N.B.1\n",
    "The name of the task_id cannot contain symbolic chars like # but just alphanumeric characters, dashes, dots, and underscores\n",
    "To avoid AirflowException\n",
    "\"\"\"\n",
    "with DAG(\n",
    "    \"tutorial\",\n",
    "    default_args={\n",
    "        \"depends_on_past\": False,\n",
    "        \"retries\": 1,\n",
    "        \"retry_delay\": timedelta(minutes=5),\n",
    "        'queue': 'bash_queue',\n",
    "        'execution_timeout': timedelta(seconds=300),\n",
    "        'trigger_rule': 'all_success'\n",
    "        # 'pool': 'backfill',\n",
    "        # 'priority_weight': 10,\n",
    "        # 'end_date': datetime(2016, 1, 1),\n",
    "        # 'wait_for_downstream': False,\n",
    "        # 'sla': timedelta(hours=2),\n",
    "        # 'on_failure_callback': some_function, # or list of functions\n",
    "        # 'on_success_callback': some_other_function, # or list of functions\n",
    "        # 'on_retry_callback': another_function, # or list of functions\n",
    "        # 'sla_miss_callback': yet_another_function, # or list of functions\n",
    "    },\n",
    "    description=\"Simple DAG with Bash operator\",\n",
    "    schedule=timedelta(days=1),\n",
    "    start_date=datetime(2021, 1, 1),\n",
    "    catchup=False,\n",
    "    tags=[\"simple_example_1\"],\n",
    ") as dag:\n",
    "    ######################################## Create tasks by instantiating operators\n",
    "    print_date_0 = BashOperator(\n",
    "        task_id=\"print_date_0\",                 \n",
    "        bash_command=\"date\",\n",
    "    )\n",
    "    create_file_1 = BashOperator(\n",
    "        task_id='create_file_1',\n",
    "        bash_command='touch ~/file_temp_1.txt',\n",
    "    )\n",
    "    write_content_2 = BashOperator(\n",
    "        task_id='write_content_2',\n",
    "        bash_command='echo \"Sample content to insert just to testing. Ok works \" > ~/file_temp_1.txt',\n",
    "    )\n",
    "    modify_content_3 = BashOperator(\n",
    "        task_id='modify_content_sed_3',\n",
    "        bash_command='sed -i \"s/content/text/g\" ~/file_temp_1.txt',\n",
    "    )\n",
    "    flow_operator_3 = BashOperator(\n",
    "        task_id='flow_operator_3',\n",
    "        bash_command='echo \"Flow step 3\"',\n",
    "    )    \n",
    "    process_content_4 = BashOperator(\n",
    "        task_id='process_content_awk_4',\n",
    "        bash_command='awk \\'{print $1}\\' ~/file_temp_1.txt > ~/file_temp_2.txt',\n",
    "    )\n",
    "    sleep_5 = BashOperator(\n",
    "        task_id=\"sleep_5\",\n",
    "        # depends_on_past => What is the the relationship of a task with its previous instances within the same DAG,\n",
    "        # across different schedule intervals or runs?\n",
    "        # No => False => the task does not depend on the success of its previous runs.\n",
    "        # The task will run, regardless of the success or failure of its previous instance.\n",
    "        depends_on_past=False,\n",
    "        bash_command=\"sleep 5\",\n",
    "        retries=3,\n",
    "    )\n",
    "    process_content_6 = BashOperator(\n",
    "        task_id='read_file_6',\n",
    "        bash_command='cat ~/file_temp_2.txt',\n",
    "    )\n",
    "    remove_file_7 = BashOperator(\n",
    "        task_id='remove_file_7',\n",
    "        bash_command='rm  ~/file_temp_1.txt',\n",
    "    )\n",
    "    flow_operator_7 = BashOperator(\n",
    "        task_id='flow_operator_7',\n",
    "        bash_command='echo \"File 1 cancelled\"',\n",
    "    )    \n",
    "    remove_file_8 = BashOperator(\n",
    "        task_id='remove_file_8',\n",
    "        bash_command='rm  ~/file_temp_2.txt',\n",
    "    )\n",
    "    \n",
    "    \"\"\" Jinja templating engine:\n",
    "    textwrap.dedent() creates a multi-line command string (the templated command)\n",
    "    Jinja templating can be used to incorporate dynamic elements based on the context of the DAG run.\n",
    "    For instance, {{ ds }} is a template variable for the execution date as a YYYY-MM-DD string.\n",
    "    \"\"\"\n",
    "    # Add a documentation anywhere\n",
    "    dag.doc_md = \"\"\" Documentation Read me\"\"\"  \n",
    "    \n",
    "    ############ Use Jinja\n",
    "    \"\"\" For each run of the DAG, replace {{ ds }} with the execution date and {{ macros.ds_add(ds, 7) }} ...\n",
    "    with the execution date plus 7 days \"\"\"\n",
    "    templated_command = textwrap.dedent(\"\"\"\n",
    "        {% for i in range(11) %}\n",
    "            echo \"{{ ds }}\"\n",
    "            echo \"{{ macros.ds_add(ds, 7)}}\"\n",
    "        {% endfor %}\n",
    "    \"\"\"\n",
    "    )\n",
    "    final_task_11 = BashOperator(\n",
    "        task_id=\"templated_11\",\n",
    "        depends_on_past=False,\n",
    "        bash_command=templated_command,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkturquoise;\"> Recap: Jinja templating </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "Jinja templating in Apache Airflow is quite powerful and offers a variety of variables and macros that you can use to create dynamic task definitions and commands.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use set_upstream and set_downstream for defining task workflow\n",
    "task2.set_upstream(task1)   => task1 will run before task2. Then task2 depends on task1\n",
    "task2.set_downstream(task1) => task2 will run before task1.\n",
    "\"\"\"\n",
    "print_date_0.set_downstream(create_file_1)\n",
    "create_file_1.set_downstream(write_content_2)\n",
    "write_content_2.set_downstream(modify_content_3)\n",
    "modify_content_3.set_downstream(flow_operator_3)\n",
    "flow_operator_3.set_downstream(process_content_4)\n",
    "process_content_4.set_downstream(sleep_5)\n",
    "sleep_5.set_downstream(process_content_6)\n",
    "process_content_6.set_downstream(remove_file_7)\n",
    "remove_file_7.set_downstream(flow_operator_7)\n",
    "flow_operator_7.set_downstream(remove_file_8)\n",
    "\n",
    "\"\"\"\n",
    "print_date_0 >> \\\n",
    "create_file_1 >> \\\n",
    "write_content_2 >> \\\n",
    "modify_content_3 >> \\\n",
    "flow_operator_3 >> \\\n",
    "process_content_4 >> \\\n",
    "sleep_5 >> \\\n",
    "process_content_6 >> \\\n",
    "remove_file_7  >> \\\n",
    "flow_operator_7 >> \\\n",
    "remove_file_8\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: darkturquoise;\"> Example #3 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping since the requirement is already satisfied\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping since the requirement is already satisfied\n",
    "!pip install psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_function_get_information():\n",
    "    cpu_usage = psutil.cpu_percent()\n",
    "    memory_usage = psutil.virtual_memory().percent\n",
    "    disk_usage = psutil.disk_usage('/').percent\n",
    "\n",
    "    report = f\"System Statistics Report:\\n\"\n",
    "    report += f\"CPU Usage: {cpu_usage}%\\n\"\n",
    "    report += f\"Memory Usage: {memory_usage}%\\n\"\n",
    "    report += f\"Disk Usage: {disk_usage}%\\n\"\n",
    "\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': datetime(2024, 1, 14),\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag_3 = DAG(\n",
    "    'system_stats_dag',\n",
    "    default_args=default_args,\n",
    "    description='A simple DAG to report system stats',\n",
    "    schedule=timedelta(days=1), # schedule_interval is deprecated!\n",
    ")\n",
    "\n",
    "system_stats_task = PythonOperator(\n",
    "    task_id='report_system_stats',\n",
    "    python_callable=third_function_get_information,\n",
    "    dag=dag_3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(PythonOperator): report_system_stats>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_stats_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: darkturquoise;\"> Example #4</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_task():\n",
    "    import requests\n",
    "    \n",
    "    city = \"London\"\n",
    "    api_key = \"your_api_key\" \n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        weather = data['weather'][0]['description']\n",
    "        # Convert from Kelvin to Celsius\n",
    "        temperature = data['main']['temp'] - 273.15  \n",
    "        print(f\"Current weather in {city}: {weather}, Temperature: {temperature:.2f}Â°C\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve weather data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(PythonOperator): fetch_weather>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Some options for schedule \"\"\"\n",
    "dag_4 = DAG('weather_data_dag',\n",
    "    default_args=default_args,\n",
    "    description='A simple DAG to fetch weather data',\n",
    "    schedule=\"0 0 * * *\",       # daily at midnight Cron Expressions\n",
    "    #schedule=\"@daily\",         # Presets\n",
    "    #schedule=\"@hourly\",        #\n",
    "    #schedule=\"@yearly\",        # on January 1st at midnight\n",
    "    #schedule=\"0 0 * * 0\",      # weekly on Sunday at midnight\n",
    "    #schedule=\"*/15 * * * *\",   # every 15 minutes \n",
    "    #schedule=\"0 0 1 * *\",      # monthly on the 1st day at midnight\n",
    "    #schedule=\"0 12 */5 * *\",   # every 5 Days at Noon:\n",
    "    #schedule=\"0 19 * * 1,3,5\", # every Monday, Wednesday, and Friday at 7 PM\n",
    "    #schedule=\"0 */6 * * *\",    # every 6 hours\n",
    ")\n",
    "\n",
    "weather_task = PythonOperator(\n",
    "    task_id='fetch_weather',\n",
    "    python_callable=get_weather_task,\n",
    "    dag=dag_4,\n",
    ")\n",
    "\n",
    "weather_task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
